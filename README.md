# ğŸŒ¸ Iris Flower Recognition using CNNs

This project presents a deep learning-based image classification system to recognize **Iris flower species** using **Convolutional Neural Networks (CNNs)**. Leveraging the `tf_flowers` dataset from TensorFlow Datasets, this model achieves **93.49% test accuracy**, showcasing the power of CNNs in solving real-world classification problems in botany, computer vision, and biodiversity research.

---

## ğŸ“Œ Project Overview

This project was developed as part of my coursework for the **Artificial Neural Networks (ANN)** module. The main objective was to implement a **CNN-based classifier** that could accurately recognize five different species of flowers â€” **daisy, dandelion, rose, sunflower, and tulip** â€” from images using deep learning frameworks.

---

## ğŸ§  Technologies & Tools Used

- **Language**: Python 3.10
- **Frameworks**: TensorFlow 2.19, Keras 3.9.1
- **Libraries**: NumPy, Matplotlib, Seaborn, OpenCV
- **Platform**: Jupyter Notebook (Google Colab TPU)
- **Dataset**: [`tf_flowers`](https://www.tensorflow.org/datasets/catalog/tf_flowers) from TensorFlow Datasets

---

## ğŸ” Problem Statement

The Iris Flower Recognition problem involves multi-class image classification using a CNN trained on raw image data. It aims to:
- Automate plant species recognition
- Contribute to biodiversity conservation
- Explore CNN performance in image classification with limited data

---

## ğŸ¯ Project Goals

- ğŸ“ Preprocess and augment image data for improved generalization
- ğŸ§± Design a CNN architecture with Conv, Pooling, Dense, Dropout layers
- ğŸƒâ€â™‚ï¸ Train and evaluate the model on the `tf_flowers` dataset
- ğŸ“ˆ Visualize accuracy/loss and analyze predictions
- ğŸ’¾ Save and reload the trained model for reuse

---

## ğŸ—‚ï¸ Dataset Details

- **Classes**: Daisy, Dandelion, Rose, Sunflower, Tulip
- **Total Images**: 3,670
- **Data Source**: [TensorFlow Datasets - tf_flowers](https://www.tensorflow.org/datasets/catalog/tf_flowers)
- **Preprocessing**:
  - Resized to 128Ã—128 pixels
  - Normalized pixel values to [0,1]
  - One-hot encoded labels

---

## ğŸ”§ Model Architecture

| Layer                | Details                                 |
|---------------------|-----------------------------------------|
| Input               | 128x128x3 RGB Image                     |
| Conv2D + ReLU       | 32 filters, 3x3 kernel                  |
| MaxPooling2D        | 2x2 pool size                           |
| Conv2D + ReLU       | 64 filters, 3x3 kernel                  |
| MaxPooling2D        | 2x2 pool size                           |
| Conv2D + ReLU       | 128 filters, 3x3 kernel                 |
| MaxPooling2D        | 2x2 pool size                           |
| Flatten             | â€”                                       |
| Dense + ReLU        | 128 units                               |
| Dropout             | 0.5                                     |
| Output (Softmax)    | 5 units (one per flower class)          |

---

## âš™ï¸ Training Configuration

- **Optimizer**: Adam
- **Loss Function**: Sparse Categorical Crossentropy
- **Epochs**: 100
- **Batch Size**: 32
- **Hardware**: TPU-accelerated environment (Google Colab)

---

## ğŸ“Š Performance

| Metric        | Value           |
|---------------|------------------|
| Training Accuracy | ~95%          |
| Test Accuracy     | **93.49%**     |
| Correct Predictions | All 5 classes |
| Sample Confidence | 97â€“99%        |

---

## ğŸŒ± Data Augmentation Techniques

- Horizontal Flip
- Random Rotation
- Random Zoom

These techniques helped to reduce overfitting, balance class representation, and improve generalization.

---

## ğŸ§ª Example Predictions

| Flower Type | Predicted Class | Confidence |
|-------------|------------------|------------|
| ğŸŒ¼ Daisy    | Daisy            | 97.6%      |
| ğŸŒ¹ Rose     | Rose             | 99.95%     |
| ğŸŒ» Sunflower| Sunflower        | 98.32%     |
| ğŸŒ· Tulip    | Tulip            | 99.98%     |
| ğŸŒ¼ Dandelion| Dandelion        | 98.45%     |

---

## âœ… Key Takeaways

- CNNs are robust for spatial feature learning and image classification tasks
- Preprocessing and data augmentation significantly improved model performance
- Transfer learning, larger datasets, and ensemble models can be explored for further optimization

---

## ğŸ“Œ Future Improvements

- Use **pretrained models** like ResNet or MobileNet for transfer learning
- Add **confusion matrix** and **classification report**
- Optimize with **hyperparameter tuning**
- Build a **web UI** for real-time flower image classification

---

## ğŸ“ Project Structure

